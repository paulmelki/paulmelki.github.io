---
title: "The COVID-19 Initial Unemployment Claims Spike in Context"
output:
  md_document:
    variant: gfm
    preserve_yaml: TRUE
knit: (function(inputFile, encoding) {
   rmarkdown::render(inputFile, encoding = encoding, output_dir = "../_posts") })
author: "steve"
date: '2020-03-26'
excerpt: "The first data on COVID-19's effect on unemployment rates are out and... holy cow."
layout: post
categories:
  - R
image: "woman-mask-la-covid19.jpg"
---

```{r setup, include=FALSE, cache=F}

base_dir <- "~/Dropbox/svmiller.github.io/"
base_url <- "/"
fig_path <- "images/"

add_jekyll_image <- function(url, caption, width, align) {
 img <- paste0('{% include image.html url="',url,'" caption="',caption,'" width=',width,' align="',align,'" %}')
 cat(img)
}

knitr::opts_knit$set(base.dir = base_dir, base.url = base_url)
knitr::opts_chunk$set(fig.path = fig_path, dpi= 300,
                      cache.path = '../cache/covid19-initial-claims/',
                      message=FALSE, warning=FALSE,
                      cache = TRUE) 

library(tidyverse) # for most things. This is the best workflow package out there.
library(stevemisc)
library(fredr)
library(lubridate)
library(knitr)
library(kableExtra)

fredr(series_id = "ICSA",
        observation_start = as.Date("1967-01-01")) -> ICSA

# Initial claims data
stateclaimsabbs <- paste0(c(state.abb),"ICLAIMS")

sclaims <- tibble()

for (i in 1:length(stateclaimsabbs)) {
  fredr(series_id = stateclaimsabbs[i],
        observation_start = as.Date("1986-01-01")) -> hold_this
    bind_rows(sclaims, hold_this) -> sclaims
}


# fredr(series_id = "CLF16OV",
#         observation_start = as.Date("1967-01-01")) -> CLF
# 
# fredr(series_id = "POPTHM",
#         observation_start = as.Date("1967-01-01")) -> Pop
# 
# fredr(series_id = "CIVPART",
#         observation_start = as.Date("1967-01-01")) -> Civpart
# 
# tribble(~date,
#         seq(ymd('1967-01-01'), ymd(today()), by = '1 day')) %>%
#         unnest(date) -> Dates
# 
# Dates %>%
#   left_join(., ICSA %>% select(-series_id)) %>%
#   rename(claims = value) %>%
#   left_join(., Pop %>% select(-series_id)) %>%
#   rename(pop = value) %>%
#   left_join(., Civpart %>% select(-series_id)) %>%
#   rename(civpart = value) %>%
#   mutate(workpopest = pop *(civpart/100)) %>%
#   fill(pop, civpart, workpopest) %>%
#   filter(!is.na(claims)) %>%
#   mutate(prop = (claims/1000)/workpopest) %>%
#   ggplot(.,aes(date, prop)) +
#   theme_steve_web() + post_bg() +
#   scale_x_date(date_breaks = "2 years",
#                date_labels = "%Y",
#                limits = as.Date(c('1965-01-01','2020-04-01'))) +
#   geom_rect(data=filter(recessions,year(peak)>1966), inherit.aes=F, 
#             aes(xmin=peak, xmax=trough, ymin=-Inf, ymax=+Inf), fill='darkgray', alpha=0.8) +
#      geom_line() 
#     geom_ribbon(aes(ymin=-Inf, ymax=value/1000),
#               alpha=0.3, fill="#619CFF") +
#   scale_y_continuous(labels = scales::comma) +
#   labs(title = "Initial Unemployment Claims From January 7, 1967 to March 21, 2020",
#        subtitle = "The almost 3.3 million unemployment claims dwarfs the unemployment effects of the major recessions in the data.",
#        x = "", y = "Unemployment Claims (in Thousands)",
#        caption = "Data: U.S. Employment and Training Administration (initial claims), National Bureau of Economic Research (recessions).") 

```

```{r leadimage, echo=F, eval=T, results="asis", cache=F}
 
add_jekyll_image('/images/woman-mask-la-covid19.jpg', "A woman walks wearing a mask to protect herself from the novel coronavirus (COVID-19) in front of a closed theater in Koreatown, Los Angeles, on March 21, 2020. (AFP, GETTY IMAGES)", "400", "right")
 
```


*Last updated: `r format(Sys.time(), '%B %d, %Y')`* 

The U.S. Employment and Training Administration released its weekly update on initial unemployment claims, giving us the first glimpse of the economic implications of the COVID-19 pandemic beyond [the fluctuation we're observing in the stock market](http://svmiller.com/blog/2020/03/dow-jones-no-good-very-bad-day/). And... [yikes](https://www.cnn.com/2020/03/26/economy/unemployment-benefits-coronavirus/index.html).

The data are grisly and some R code will illustrate that. First, here are the packages necessary to put this unemployment claims spike in context. `tidyverse` comes at the fore of my workflow. `stevemisc` is my toy R package, which incidentally has a data set on U.S. recessions (`recessions`) for added context. It should be no surprise that unemployment climbs during these periods. Finally, `fredr` interacts with the Federal Reserve Economic Data maintained by the research division of the Federal Reserve Bank of St. Louis. The API is the easiest and most flexible of any I've used and I wish the IMF's API were as simple. `lubridate` will help us play with dates.

```r
library(tidyverse)
library(stevemisc)
library(fredr)
library(lubridate)
```

The `fredr` call is simple. The initial unemployment claims data has [a series id of "ICSA"](https://fred.stlouisfed.org/series/ICSA) and the data extend to January 1967. Let's grab everything we can.

```r
fredr(series_id = "ICSA",
        observation_start = as.Date("1967-01-01")) -> ICSA
```

Here's what the data looked like before today.

```{r initial-claims-data-1967-before-covid19, echo=T, eval=T, cache=T, warning=F, fig.width=13, fig.height = 8}

ICSA %>%
  filter(date <= ymd("2020-03-14")) %>%
  ggplot(.,aes(date, value/1000)) +
  theme_steve_web() + post_bg() +
  scale_x_date(date_breaks = "2 years",
               date_labels = "%Y",
               limits = as.Date(c('1965-01-01','2020-04-01'))) +
  geom_rect(data=filter(recessions,year(peak)>1966), inherit.aes=F, 
            aes(xmin=peak, xmax=trough, ymin=-Inf, ymax=+Inf), fill='darkgray', alpha=0.8) +
     geom_line() +
    geom_ribbon(aes(ymin=-Inf, ymax=value/1000),
              alpha=0.3, fill="#619CFF") +
  labs(title = "Initial Unemployment Claims From January 7, 1967 to March 14, 2020",
       subtitle = "Unemployment claims clearly rise during economic contractions with peaks observed during the early 1980s global recession and the Great Recession from 2007-2009.",
       x = "", y = "Unemployment Claims (in Thousands)",
       caption = "Data: U.S. Employment and Training Administration (initial claims), National Bureau of Economic Research (recessions).") 
```

The peaks in the early 1980s and from 2007 to 2009 are immediately evident. Those periods coincided with global recessions in which the unemployment rate in the U.S. (calculated monthly) [exceeded 10% of the civilian labor force](https://fred.stlouisfed.org/series/UNRATE). 

Now, here's what the data look like as of today.

```{r initial-claims-data-1967-first-week-of-covid19, echo=T, eval=T, cache=T, warning=F, fig.width=12, fig.height = 8}

ICSA %>%
  # change just one line
  filter(date <= ymd("2020-03-21"))  %>% # Commenting out just one line.
  ggplot(.,aes(date, value/1000)) +
  theme_steve_web() + post_bg() +
  scale_x_date(date_breaks = "2 years",
               date_labels = "%Y",
               limits = as.Date(c('1965-01-01','2020-04-01'))) +
  geom_rect(data=filter(recessions,year(peak)>1966), inherit.aes=F, 
            aes(xmin=peak, xmax=trough, ymin=-Inf, ymax=+Inf), fill='darkgray', alpha=0.8) +
     geom_line() +
    geom_ribbon(aes(ymin=-Inf, ymax=value/1000),
              alpha=0.3, fill="#619CFF") +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Initial Unemployment Claims From January 7, 1967 to March 21, 2020",
       subtitle = "The almost 3.3 million unemployment claims dwarfs the unemployment effects of the major recessions in the data.",
       x = "", y = "Unemployment Claims (in Thousands)",
       caption = "Data: U.S. Employment and Training Administration (initial claims), National Bureau of Economic Research (recessions).") 
```

I'll come back and update this when the states roll out their updates, but it does have me thinking about this dire warning from the President of the Federal Reserve Bank of St. Louis.

<center>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">JUST IN: Fed&#39;s Bullard says U.S. unemployment rate may hit 30% in the second quarter <a href="https://t.co/kdy6npXQAS">https://t.co/kdy6npXQAS</a></p>&mdash; Bloomberg (@business) <a href="https://twitter.com/business/status/1241812970549755905?ref_src=twsrc%5Etfw">March 22, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></center>

Standardizing initial claims to the (growing) civilian labor force of the United States lends to some worry that estimate might be too low. Basically, the initial claims as a proportion of the civilian labor force, right now, is **four times** what it was at the peak of the Great Recession and the early 1980s recession. Therein, the unemployment rate was between 10-11%. The extent to which initial claims is a sneak peek of the monthly unemployment rate, 30% might be too low an estimate.

Alas, I'll defer to the President of the FRED's division in St. Louis. He'll know more than me. I just know how to play with the data that his research division releases.

### Update for April 2, 2020

*Gulp.*

```{r initial-claims-data-1967-starting-with-covid19, echo=T, eval=T, cache=T, warning=F, fig.width=12, fig.height = 8}

ICSA %>%
  # Omit the filter
  #filter(date <= ymd("2020-03-21"))  %>% # Commenting out just one line.
  ggplot(.,aes(date, value/1000)) +
  theme_steve_web() + post_bg() +
  scale_x_date(date_breaks = "2 years",
               date_labels = "%Y",
               limits = as.Date(c('1965-01-01','2020-04-01'))) +
  geom_rect(data=filter(recessions,year(peak)>1966), inherit.aes=F, 
            aes(xmin=peak, xmax=trough, ymin=-Inf, ymax=+Inf), fill='darkgray', alpha=0.8) +
     geom_line() +
    geom_ribbon(aes(ymin=-Inf, ymax=value/1000),
              alpha=0.3, fill="#619CFF") +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Initial Unemployment Claims From January 7, 1967 to the Present",
       subtitle = "The ongoing COVID-19 pandemic makes the initial claims spikes of the early 1980s and mid-2000s almost invisible.",
       x = "", y = "Unemployment Claims (in Thousands)",
       caption = "Data: U.S. Employment and Training Administration (initial claims), National Bureau of Economic Research (recessions).") 
```

The state-level initial claims data also offer an insight to what COVID-19 has done to unemployment. These indicators seem to lag a week behind the national figures so the most recent national update for today (*gulp*) also comes with more insight to the jarring statistics released last week.

This script will grab the most current data for initial claims for all 50 states.

```r
# Initial claims data
stateclaimsabbs <- paste0(c(state.abb),"ICLAIMS")

sclaims <- tibble()

for (i in 1:length(stateclaimsabbs)) {
  fredr(series_id = stateclaimsabbs[i],
        observation_start = as.Date("1986-01-01")) -> hold_this
    bind_rows(sclaims, hold_this) -> sclaims
}
```

This will show which states were hit the hardest by the spate of unemployment claims starting last week. 

```r
sclaims %>%
  mutate(state = str_sub(series_id, 1, 2)) %>%
  group_by(state) %>%
  mutate(l1_value = lag(value, 1),
         diff = (value - l1_value)/l1_value,
         diff = diff*100) %>%
  slice(n()) %>%
  arrange(-diff)
```

```{r, eval=T, echo=F}
sclaims %>%
  mutate(state = str_sub(series_id, 1, 2)) %>%
  group_by(state) %>%
  mutate(l1_value = lag(value, 1),
         diff = (value - l1_value)/l1_value,
         diff = diff*100) %>%
  slice(n()) %>%
  arrange(-diff) %>% select(-series_id) %>%
  mutate(diff = paste0(round(diff, 2), "%")) %>% 
  ungroup() %>%
  mutate(rank = seq(1,n())) %>%
  select(rank, state, everything(), -date)  %>%
     kable(., format="html", table.attr='id="stevetable"',
        col.names=c("Rank", "State", "Initial Claims (March 21, 2020)", "Initial Claims (March 14, 2020)", "% Change"),
        caption = "COVID-19's First Effect on Unemployment Claims, by State",
        align=c("c","l","c","c","c","c"))
```


Basically, every state was rocked, some more than others. New Hampshire saw the largest increase from March 14 to March 21. Only 642 people in New Hampshire filed a new jobless claim in the March 14 update. That number skyrocketed to 29,379 in the March 21 update. That is a change of over 4,476 percent. There are four curious states at the bottom: Mississippi, West Virginia, California, and Georgia. To be clear, all four had massive increases from the previous week, all at least doubling from the previous week. West Virginia and Mississippi even tripled. However, California stands out as taking more proactive measures quicker than the other three states, which might suggest worse is yet to come for states like Mississippi and Georgia. For example, [Mississippi's governor rejected calls for a lockdown](https://www.jacksonfreepress.com/news/2020/mar/23/governor-rejects-state-lockdown-covid-19-mississip/) on March 23 by claiming the state will "never be China" on the COVID-19 front. Now, it has [the country's highest hospitalization rate for COVID-19](https://mississippitoday.org/2020/04/01/mississippi-has-nations-highest-covid-19-hospitalization-rate/). Georgia's governor [similarly downplayed COVID-19](https://www.vanityfair.com/news/2020/04/georgias-governor-apparently-just-learned-how-coronavirus-works) before finally [rolling out a shelter-in-place order](https://www.gpbnews.org/post/georgia-coronavirus-updates-kemp-orders-shelter-place). The economic consequences of these later measures we're seeing in the Deep South may manifest in subsequent updates.

```{r knitchunk, echo=F, eval=F}
setwd("~/Dropbox/svmiller.github.io/_source")
knitr::knit("2020-03-26-the-covid19-initial-claims-spike-in-context-r.Rmd",
            output = "../_posts/2020-03-26-the-covid19-initial-claims-spike-in-context-r.md")

```
